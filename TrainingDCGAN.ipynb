{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "seed = 999\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "num_workers=1\n",
    "dim_z = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.structure = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=dim_z, out_channels=512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.structure(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.structure = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        return self.structure(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./Human_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    name = m.__class__.__name__\n",
    "    if (name.find(\"Conv\") != -1):\n",
    "        nn.init.normal_(m.weight.data, 0., 0.02) # ~N(mean=0, std=0.02)\n",
    "    elif (name.find(\"BatchNorm\") != -1):\n",
    "        nn.init.normal_(m.weight.data, 1., 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_G = Generator(ngpu=1)\n",
    "if (device.type == \"cuda\" and ngpu > 1):\n",
    "    model_G = nn.DataParallel(model_G, list(range(ngpu)))\n",
    "# Weights initialization\n",
    "model_G.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_D = Discriminator(ngpu=1)\n",
    "if (device == \"cuda\" and ngpu > 1):\n",
    "    model_D = nn.DataParallel(model_D, list(range(ngpu)))\n",
    "# Initialize weights for the Discriminator\n",
    "model_D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(data_dir, img_size, bs):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True, num_workers=4)\n",
    "    return dataloader\n",
    "# Tạo hàm train mô hình DCGAN\n",
    "def train_DCGAN(data_dir, bs, dim_z, NUM_EPOCHS, lr):\n",
    "    # Khởi tạo DataLoader cho tập dữ liệu\n",
    "    dataloader = create_dataloader(data_dir, img_size, bs)\n",
    "\n",
    "    # Chọn hàm mất mát và tối ưu hóa\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizerD = optim.Adam(model_D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizerG = optim.Adam(model_G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    model_D.to(device)\n",
    "    model_G.to(device)\n",
    "\n",
    "    # Lặp qua số epochs\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        total_loss_D = 0.0\n",
    "        total_loss_G = 0.0\n",
    "        num_batches = len(dataloader)\n",
    "        \n",
    "        for images, _ in iter(dataloader):   \n",
    "            model_D.zero_grad()\n",
    "            # Define log(D(x))\n",
    "            real_imgs = images.to(device)\n",
    "            bs = real_imgs.size(0) # batch size\n",
    "            \n",
    "            labels = torch.full(size=(bs,), fill_value=1.0, dtype=torch.float, device=device)\n",
    "            outputs = model_D(real_imgs).view(-1)     \n",
    "            lossD_real = criterion(outputs, labels)\n",
    "            lossD_real.backward() # this will be automatically accumulated with lossD_fake in PyTorch\n",
    "            \n",
    "            # Define log(1-D(G(z)))\n",
    "            z = torch.randn(size=(bs, dim_z, 1, 1), device=device, requires_grad=False)\n",
    "            fake_imgs = model_G(z)\n",
    "            \n",
    "            labels.fill_(0.0) # fake images\n",
    "            outputs = model_D(fake_imgs.detach()).view(-1) \n",
    "            lossD_fake = criterion(outputs, labels)\n",
    "            lossD_fake.backward() # this is automatically accumulated with lossD_real in PyTorch\n",
    "            \n",
    "            optimizerD.step()\n",
    "            total_loss_D += (lossD_real + lossD_fake).item()\n",
    "\n",
    "            model_G.zero_grad()\n",
    "            \n",
    "            labels.fill_(1.0)\n",
    "            outputs = model_D(fake_imgs).view(-1) # now the fake images are given label \"real\" to optimize G\n",
    "            lossG = criterion(outputs, labels)\n",
    "            lossG.backward()\n",
    "            \n",
    "            optimizerG.step()\n",
    "            total_loss_G += lossG.item()\n",
    "        # In loss sau mỗi epoch\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] - Loss_D: {total_loss_D / num_batches:.4f}, Loss_G: {total_loss_G / num_batches:.4f}\")\n",
    "    mse_loss = torch.mean((real_imgs - fake_imgs) ** 2)  # Tính mean squared error\n",
    "    return mse_loss.item()  # Trả về giá trị mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "param_grid = {\n",
    "    \"NUM_EPOCHS\": [30, 50, 100],\n",
    "    \"bs\": [64, 128],\n",
    "    \"lr\": [0.0001, 0.0002, 0.0005]\n",
    "}\n",
    "\n",
    "# Lặp qua các giá trị siêu tham số\n",
    "best_loss = float(\"inf\")\n",
    "best_hyperparameters = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    NUM_EPOCHS = params[\"NUM_EPOCHS\"]\n",
    "    bs = params[\"bs\"]\n",
    "    lr = params[\"lr\"]\n",
    "\n",
    "    # Train mô hình với các siêu tham số hiện tại\n",
    "    current_loss = train_DCGAN(data_dir, bs, dim_z, NUM_EPOCHS, lr)\n",
    "\n",
    "    # Lưu siêu tham số tốt nhất nếu loss tốt hơn\n",
    "    if current_loss < best_loss:\n",
    "        best_loss = current_loss\n",
    "        best_hyperparameters = params\n",
    "        # Lưu model tốt nhất\n",
    "        model_D_path = \"./Model/best_model_D.pth\"\n",
    "        model_G_path = \"./Model/best_model_G.pth\"\n",
    "        torch.save(model_D.state_dict(), model_D_path)\n",
    "        torch.save(model_G.state_dict(), model_G_path)\n",
    "# In ra các siêu tham số tối ưu\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
