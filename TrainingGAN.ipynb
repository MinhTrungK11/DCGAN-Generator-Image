{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image as Img\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Reshape, LeakyReLU, Conv2D, Conv2DTranspose, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as pil\n",
    "from pkg_resources import parse_version\n",
    "if parse_version(pil.__version__)>=parse_version('10.0.0'):\n",
    "    Image.ANTIALIAS=Image.LANCZOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "IMAGES_COUNT = 8000\n",
    "PIC_DIR = f'E:/HKI_Year4/UI_TLCN/CelebFaces_Data/cele_data/'\n",
    "\n",
    "ORIG_WIDTH = 178\n",
    "ORIG_HEIGHT = 208\n",
    "diff = (ORIG_HEIGHT - ORIG_WIDTH) // 2\n",
    "\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "\n",
    "crop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff)\n",
    "\n",
    "images = []\n",
    "for pic_file in tqdm(os.listdir(PIC_DIR)[:IMAGES_COUNT]):\n",
    "    pic = Image.open(PIC_DIR + pic_file).crop(crop_rect)\n",
    "    pic.thumbnail((WIDTH, HEIGHT), Image.ANTIALIAS)\n",
    "    images.append(np.uint8(pic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image shape\n",
    "images = np.array(images) / 255\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display first 25 images\n",
    "plt.figure(1, figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 32\n",
    "CHANNELS = 3\n",
    "def create_generator():\n",
    "    gen_input = Input(shape=(LATENT_DIM, ))\n",
    "\n",
    "    x = Dense(128)(gen_input)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(256)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(512)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(HEIGHT * WIDTH * CHANNELS, activation='tanh')(x)\n",
    "    x = Reshape((HEIGHT, WIDTH, CHANNELS))(x)\n",
    "\n",
    "    generator = Model(gen_input, x)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    disc_input = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n",
    "\n",
    "    x = Conv2D(256, 3)(disc_input)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(256, 4, strides=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(256, 4, strides=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(256, 4, strides=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(256, 4, strides=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(disc_input, x)\n",
    "\n",
    "    optimizer = RMSprop(\n",
    "        lr=.0001,\n",
    "        clipvalue=1.0,\n",
    "        decay=1e-8\n",
    "    )\n",
    "\n",
    "    discriminator.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy'\n",
    "    )\n",
    "\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "generator = create_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(model_to_dot(generator, show_shapes=True).create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = create_discriminator()\n",
    "discriminator.trainable = False\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(model_to_dot(discriminator, show_shapes=True).create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_input = Input(shape=(LATENT_DIM, ))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "import numpy as np\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "def objective(trial: Trial):\n",
    "    # Các tham số không đổi\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    iters = trial.suggest_int('iters', 1000, 3000) \n",
    "    batch_size = trial.suggest_int('batch_size', 8, 16)\n",
    "\n",
    "    # Khởi tạo optimizer\n",
    "    optimizer = RMSprop(lr=lr, clipvalue=1.0, decay=1e-8)\n",
    "    gan.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "    # Khởi tạo biến để lưu mất mát\n",
    "    d_losses = []\n",
    "    a_losses = []\n",
    "\n",
    "    for step in range(iters):\n",
    "        # Sinh dữ liệu giả và huấn luyện\n",
    "        latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n",
    "        generated = generator.predict(latent_vectors)\n",
    "        real = images[start:start + batch_size]\n",
    "        combined_images = np.concatenate([generated, real])\n",
    "\n",
    "        # Huấn luyện bộ phân biệt và bộ tạo\n",
    "        labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "        labels += .05 * np.random.random(labels.shape)\n",
    "        d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "        d_losses.append(d_loss)\n",
    "\n",
    "        misleading_targets = np.zeros((batch_size, 1))\n",
    "        a_loss = gan.train_on_batch(latent_vectors, misleading_targets)\n",
    "        a_losses.append(a_loss)\n",
    "\n",
    "    # Chọn tiêu chí đánh giá\n",
    "    final_loss = np.mean(a_losses)+ np.mean(d_losses)  # hoặc np.mean(d_losses), tùy thuộc vào mục tiêu cụ thể của bạn\n",
    "    return final_loss\n",
    "\n",
    "# Tạo và chạy nghiên cứu tối ưu hóa\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)  \n",
    "\n",
    "# In kết quả tốt nhất\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('Value: ', trial.value)\n",
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "optimizer = RMSprop(lr=0.0002, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "iters = 2462\n",
    "batch_size = 8\n",
    "RES_DIR = 'res2'\n",
    "FILE_PATH = '%s/generated_%d.png'\n",
    "if not os.path.isdir(RES_DIR):\n",
    "    os.mkdir(RES_DIR)\n",
    "\n",
    "CONTROL_SIZE_SQRT = 6\n",
    "control_vectors = np.random.normal(size=(CONTROL_SIZE_SQRT**2, LATENT_DIM)) / 2\n",
    "\n",
    "start = 0\n",
    "d_losses = []\n",
    "a_losses = []\n",
    "images_saved = 0\n",
    "for step in range(iters):\n",
    "    start_time = time.time()\n",
    "    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n",
    "    generated = generator.predict(latent_vectors)\n",
    "\n",
    "    real = images[start:start + batch_size]\n",
    "    combined_images = np.concatenate([generated, real])\n",
    "\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "    labels += .05 * np.random.random(labels.shape)\n",
    "\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    d_losses.append(d_loss)\n",
    "\n",
    "    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "\n",
    "    a_loss = gan.train_on_batch(latent_vectors, misleading_targets)\n",
    "    a_losses.append(a_loss)\n",
    "\n",
    "    start += batch_size\n",
    "    if start > images.shape[0] - batch_size:\n",
    "        start = 0\n",
    "    print(step)\n",
    "    if step % 50 == 49:\n",
    "        gan.save_weights('/gan_model.h5')\n",
    "\n",
    "        print('%d/%d: d_loss: %.4f,  a_loss: %.4f.  (%.1f sec)' % (step + 1, iters, d_loss, a_loss, time.time() - start_time))\n",
    "\n",
    "        control_image = np.zeros((WIDTH * CONTROL_SIZE_SQRT, HEIGHT * CONTROL_SIZE_SQRT, CHANNELS))\n",
    "        control_generated = generator.predict(control_vectors)\n",
    "        \n",
    "        for i in range(CONTROL_SIZE_SQRT ** 2):\n",
    "            x_off = i % CONTROL_SIZE_SQRT\n",
    "            y_off = i // CONTROL_SIZE_SQRT\n",
    "            control_image[x_off * WIDTH:(x_off + 1) * WIDTH, y_off * HEIGHT:(y_off + 1) * HEIGHT, :] = control_generated[i, :, :, :]\n",
    "        im = Img.fromarray(np.uint8(control_image * 255))#.save(StringIO(), 'jpeg')\n",
    "        im.save(FILE_PATH % (RES_DIR, images_saved))\n",
    "        images_saved += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
